## 28/07/2023
## Lucie Ruzickova - notes and code
## RNA-Seq analysis pipeline (from raw reads to counts, steps 1) to 3))
## https://hbctraining.github.io/DGE_workshop_salmon_online/lessons/01a_RNAseq_processing_workflow.html
## overview: 
## 1) biological sample/library preparation (cDNA library, quality check for mRNA and enrichment)
##		reverse transcription to cDNA and amplify by PCR (qPCR), agilent bioanalyzer, tape station to check for length, purity etc.
##		number of replicates - the more the better (biological replicates), technical replicates are not worthwhile with NGS
## 		more biol. replicates also better than increasing sequencing depth
## 		avoiding confounding effects (uncontrolled variables) and reducing batch effects (different preparation date, time, person, device, reagents etc.)
##		pooling samples randomly, have about 30 mil. SE reads per sample (stranded), also for isoforms - ENCODE, 15 mil. reads per sample sufficient if more than 3 replicates
##		read length longer than 50 bp without primer
## 		isoforms - paired-end 30 mil. bp, novel more than 60 mil. bp, more biol. replicated, the longer read the better, careful QC analysis
## 2) sequencing - getting a FASTQ, alligning to reference transcriptome assembly that is indexed
##		sequence by Illumina (paired-end or single-end reads (SSR files - check if separated or together with paired-end data)
##		Illumina clusters roughlyl correspond to reads
##		fastQC reads
##		fragmentation and size selection (generally longer than 50 bp for optimal allignment without primers
##		primers can be trimmed but do not have to depending on the quality and interference, fastq report	
## 3) using fastq: fastQC, STAR/Qualimap, possibly use bowtie2
## OR 3) Quantify expression with Salmon, Kallisto, Sailfish
## 4) DGE and functional analysis in R (Bioconductor, functional analysis etc): 
## count matrix generated using tximport and pseudocounts (MultiQC)
#####################################################
## ChIP-seq theory
# fairly difficult, lenghty and challenging to obtain good quality material
# HTS method relying on immunoprecipitation of chromatin
# an antibody/TF/histone modifier needed that binds specifically to target sites of interest
# DNA accessibility studies complement to it
# gene regulation understanding
# others are DNase-Seq, ATAC-seq, FAIRE-seq, Hi-C, TADA, ChIA-PET, computational methods etc
# regulation of genes is complex and depends on chromatin structure
# good quality chromatin vital, as well as sufficient starting material (ChIP-seq only enriches binding sites), 10^7 cells
# crosslink proteins to DNA (of interest), fragment DNA to 200-500bp pieces, use tapestation to check (Agilent)
# then use specific antibody on sheared DNA and immunoprecipitate (Ab may have off targets...)
# reverse crosslink (remove protein), purify + identify
# often with Cut'N'Tag better signal to noise ratio
# controls are needed (signal depends on active binding sites number, immunoprecipitation efficiency and starting material number and quailty)
# open chromatin fragments more easily and repetitive sequences may seem enriched
# uneven distribution of sequence tags across the genome
# hyper-ChIPable regions, and blacklisted regions, comparing a matched control with a certain region
# controls for no immunoprecipitation and nonspecific antibody, use naked DNA, different lengths of input DNA
# antibody needs to be specific, good chromatin (depends on cell type, Ab quality, abundance and stability of region of interest, mark or protein)
# size of post-fragmented chromatin matters, stringency of washes, sonication of chromatin (exact settings), if too bing fragments - worse s/n ratio
# http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4151291/ - quality checkpoints
# reads - 50 to 150 bp, longer = better mappability, cost vs readlength
# avoid batching, sequencing depth at least 10M, stadard 20-40M for TFs
# conntrols - sequence to higher depth than samples, depth matters (s/n ratio)
# better are biological replicates (high quality sample with lower depth better than the reverse)
# BWA and Bowtie2 used for alignment to genome
# compared to RNA-seq: removal of duplicates more needed, trimming more needed, blacklisted region removal more needed
# assessment of cross correlation scores and fracation of reads in peaks needed
# chipqc, homer, chilin, diffbind softwares used
# sequencing from 5' end, bimodal pattern of peakcalling, cross-correlation
# noise is not uniform, data needed for a reliable estimation of noise
# peak calling: poisson distribution genome region window, more variance in real data, MACS uses Poisson to model local noise backgrounds
# peak callers - vary a lot in no of peaks, agree on strongesy signals
# MACS, SISSRS, spp mtc, spp wtd, QuEST, Hpeak, PeakSeq, ERANGE, MCPF, Sole-search, cisgenome, core peaks
# inspect data critically - IGV, know the peak calling parameters/change if needed, look who wrote them and if they are maintained and updated, how used are they/cited
# downstream analysis - detecting differential enrichment across samples (useful decision diagram in [Steinhauser, et al, 2016])
# ChIPseeker, Homer, ChiLin - annotation of peaks 
# ChIPseeker, GREAT, Homer, ChiLin - functional enrichment analysis
# MEME suite, ChiLin, Homer - motif discovery
# DEG analysis and TF bound genes

# QC - fastqc, allignto genome with Bowtie2, BAM filtering - Samtools, peak calling MACS2
# quality assessment - Phantompeakqualtools, ChIPQC, compare and combine peak calls - BEDtools
# visualization (deepTools, IGV), Motif Discovery - MEME, annotation and functional enrichment - GREAT
#####################################################
## FastQC
module loada fastqc
fastqc *.fastq
fastqc -t 6 *.fastq # no of threads
cutadapt -q 20 -a CTGTCTCTTATACACATCT PEO1_1.R1.fastq.gz > PEO1_1.R1.trimmed.fastq.gz 2> PEO_1.R1_file.txt
# slides for error profiles for Illumina at the bottom https://hbctraining.github.io/Intro-to-ChIPseq/lessons/02_QC_FASTQC.htmlhttps://hbctraining.github.io/Intro-to-ChIPseq/lessons/02_QC_FASTQC.html
## Bowtie2 allignment to genome
# indexes the genome with an FM Index based on the Burrows-Wheeler Transform method to keep memory requirements low for the alignment process.
# supports gaps, loca and paired-end models, at least 50 bp
# also a local alignment mode - soft clipping
# shorter - bwa and Bowtie1 as well
# For bwa, the mapping rates are higher (~ 2%), with an equally similar increase in the number of duplicate mappings identified. 
# Post-filtering this translates to a significantly higher number of mapped reads and results in a much larger number of peaks being called (30% increase)
# bwa peak calls are a superset of those called from the Bowtie2 aligments. Whether or not these additional peaks are true positives, is something that is yet to be determined.
# Bowtie2 index
module load bowtie2
bowtie2-build <path_to_reference_genome.fa> <prefix_to_name_indexes>
bowtie2 -p 2 -q --local \
-x ~/chipseq/reference_data/chr12 \
-U ~/chipseq/raw_data/H1hesc_Input_Rep1_chr12.fastq \
-S ~/chipseq/results/bowtie2/H1hesc_Input_Rep1_chr12_aln_unsorted.sam
# -p: number of processors / cores
# -q: reads are in FASTQ format
# --local: local alignment feature to perform soft-clipping
# -x: /path/to/genome_indices_directory
# -U: /path/to/FASTQ_file
# -S: /path/to/output/SAM_file
# SAM format: Heng Li et al provides a lot more detail on the specification
# header, allignment section (11 fields), r/qname, flag (additive), pos, seq, qual, mrnm, mpos, isize, mapq, cigar
# https://hbctraining.github.io/Intro-to-ChIPseq/lessons/03_align_and_filtering.html

# filtering reads
# Allowing for multiple mapped reads increases the number of usable reads and the sensitivity of peak detection; 
# however, the number of false positives may also increase [1]
# change sam to bam, sort bam by coordinate locations, filter to keep only uniquely mapped reads\
module load gcc
module load samtools
# -h: include header in output
# -S: input is in SAM format
# -b: output BAM format
# -o: /path/to/output/file
samtools view -h -S -b \
-o H1hesc_Input_Rep1_chr12_aln_unsorted.bam \
H1hesc_Input_Rep1_chr12_aln_unsorted.sam
# manual: http://www.htslib.org/doc/1.2/samtools.html
# we need to sort our BAM alignment files by genomic coordinates (instead of by name)
# -t: number of threads / cores
# -h: print SAM header before reads
# -f: format of output file (default is SAM)
# -F: set custom filter - we will be using the filter to remove duplicates, multimappers and unmapped reads.
sambamba sort -t 2 \
-o H1hesc_Input_Rep1_chr12_aln_sorted.bam \
H1hesc_Input_Rep1_chr12_aln_unsorted.bam 
sambamba view -h -t 2 -f bam \
-F "[XS] == null and not unmapped  and not duplicate" \
H1hesc_Input_Rep1_chr12_aln_sorted.bam > H1hesc_Input_Rep1_chr12_aln.bam
# after this useful to generate QC metrics using MultiQC and such
# filter out blacklisted regions
# artifact regions that tend to show artificially high signal (excessive unstructured anomalous reads mapping)
# filter before peakcalling
# ENCODE and modENCODE consortia have compiled blacklists for various species and genome versions including human, mouse, worm and fly

##### Automating QC and alignment
# multiple samples
# not from the command line alone
# using positional parameters
# ex. sh  run_analysis.sh  input.fastq  input.gtf  12
ex. #!/bin/sh
echo "I was called with $# parameters"
echo "My name is $0"
echo "My first parameter is $1"
echo "My second parameter is $2"
echo "All parameters are $@"

## sample script: 
vim chipseq_analysis_on_input_file.sh
#!/bin/bash/
# This script takes a fastq file of ChIP-seq data, runs FastQC and outputs a BAM file for it that is ready for peak calling. 
# Bowtie2 is the aligner used, and the outputted BAM file is sorted by genomic coordinates and has multi-mappers and duplicate reads removed using sambamba.
# USAGE: sh chipseq_analysis_on_input_file.sh <path to the fastq file>
## initialize a variable with an intuitive name to store the name of the input fastq file
fq=$1
## grab base of filename for naming outputs
base=`basename $fq .fastq`
echo "Sample name is $base"    
## directory with bowtie genome index
genome=~/chipseq/reference_data/chr12
## make all of the output directories
# The -p option means mkdir will create the whole path if it 
# does not exist and refrain from complaining if it does exist
mkdir -p ~/chipseq/results/fastqc
mkdir -p ~/chipseq/results/bowtie2/intermediate_bams
## set up output filenames and locations
fastqc_out=~/chipseq/results/fastqc/
## set up file names
align_out=~/chipseq/results/bowtie2/${base}_unsorted.sam
align_bam=~/chipseq/results/bowtie2/${base}_unsorted.bam
align_sorted=~/chipseq/results/bowtie2/${base}_sorted.bam
align_filtered=~/chipseq/results/bowtie2/${base}_aln.bam
## set up more variables for 2 additional directoties to help clean up the results folder
bowtie_results=~/chipseq/results/bowtie2
intermediate_bams=~/chipseq/results/bowtie2/intermediate_bams
## set up the software environment, tool versions
module load fastqc/0.11.5
module load gcc/6.2.0  
module load bowtie2/2.2.9
module load samtools/1.9
export PATH=/n/app/bcbio/tools/bin:$PATH 	# for using 'sambamba'
echo "Processing file $fq" # also set -x for debugging
# run tools
# Run FastQC and move output to the appropriate folder
fastqc $fq
mv *_fastqc.* ~/chipseq/results/fastqc/
# Run bowtie2
bowtie2 -p 6 -q --local -x $genome -U $fq -S $align_out
# Create BAM from SAM
samtools view -h -S -b -@ 6 -o $align_bam $align_out
# Sort BAM file by genomic coordinates
sambamba sort -t 6 -o $align_sorted $align_bam
# Filter out duplicates
sambamba view -h -t 6 -f bam -F "[XS] == null and not unmapped " $align_sorted > $align_filtered
# Create indices for all the bam files for visualization and QC
samtools index $align_filtered
# Move intermediate files out of the bowtie2 directory
mv $bowtie_results/${base}*sorted* $intermediate_bams

# save and run script
sh chipseq_analysis_on_input_file.sh ~/chipseq/raw_data/H1hesc_Nanog_Rep1_chr12.fastq

# SLURM in serial
# **\[DO NOT RUN THIS\]**
#!/bin/bash
#SBATCH -p short 		# partition name
#SBATCH -t 0-2:00 		# hours:minutes runlimit after which job will be killed
#SBATCH -n 6 		# number of cores requested -- this needs to be greater than or equal to the number of cores you plan to use to run your job
#SBATCH --job-name Nanog_Rep1 		# Job name
#SBATCH -o %j.out			# File to which standard out will be written
#SBATCH -e %j.err 		# File to which standard error will be written
# this `for` loop, will take chip-seq fastq files as input and output filtered BAM files ready for peak calling.
for fq in ~/chipseq/raw_data/*.fastq
do
  echo "running analysis on $fq"
  sh chipseq_analysis_on_input_file.sh $fq
done
# run it
sbatch chipseq_analysis_on_allfiles.slurm
# on all files in parallel via SLURM
vim chipseq_analysis_on_allfiles_for-slurm.sh
#! /bin/bash
for fq in ~/chipseq/raw_data/*.fastq
do
sbatch -p short -t 0-2:00 -n 6 --job-name chipseq-analysis -o %j.out -e %j.err \
--wrap="sh ~/chipseq/scripts/chipseq_analysis_on_input_file.sh $fq"
sleep 1	    # wait 1 second between each job submission
done
# sacct login_ID # to check progress
# scancel to kill jobs

## Genome feature datafiles
# BED, Wiggle, GTF, GFF
# BED file: 0-based, has chr, start, end, 1 line per feature, name, phase (RF), strand
# BedGraph - 0-based, not compressed, similar to BED file, includes tracklines, score in column 4 not 5
# Wiggle - 1-based, compressed, bigWig also 1-based
# http://genome.ucsc.edu/FAQ/FAQformat.html

## PEAK CALLING
# strand asymmetry with read densities on the +/- strand, centered around the binding site. 
# Wilbanks and Faccioti, PLoS One 2010
# One of the more commonly used peak callers is MACS2, and we will demonstrate it in this session
# ChIP-seq analysis algorithms are specialized in identifying one of two types
# of enrichment: broad peaks or broad domains (i.e. histone modifications that cover entire gene bodies) 
# or narrow peaks (i.e. a transcription factor binding).
# challenge: binding properties of PolII, which binds at promotor and across the length of the gene resulting in mixed signals (narrow and broad).
## MACS2
# code: https://github.com/macs3-project/MACS
# paper: https://genomebiology.biomedcentral.com/articles/10.1186/gb-2008-9-9-r137
# improves the spatial resolution of binding sites through combining the information of both sequencing tag position and orientation

# workflow: treatment and control - remove redundancy, then with treatment - select 1000 regions qith a 10 to 30 fold enrichment relative to background,
# build a model - sestimate DNA fragment size d, shift reads towards 3' end by d, then combine treated and control samples
# the combine samples: call candidate peaks relative to genome background, caculate dynamic lambda for candidate peaks, 
# calculate P value and filter candidate peaks, calculate FDR by exchanging treatment and control

# removing redundancy - duplictes - experimental artifacts vs ChIP seq signal, some are good and some are bad (over-PCR)
# consider enrichment efficiency and sequencing depth
# A possible solution to distinguishing biological duplicate from PCR artifact would be to include UMIs into your experimental setup.
# Retain duplicates for differential binding analysis.
# If you are expecting binding in repetitive regions, use paired-end sequencing and keep duplicates.
# binding - bimodal enrichment pattern
# Given a sonication size (bandwidth) and a high-confidence fold-enrichment (mfold), 
# MACS slides two bandwidth windows across the genome to find regions with tags more than mfold enriched relative to a random tag genome distribution.
# For experiments in which sequence depth differs between input and treatment samples, MACS linearly scales the total control tag count to be the same as the total ChIP tag count.
# MAC2 requires the effective genome size or the size of the genome that is mappable. Mappability is related to the uniqueness of the k-mers at a particular position the genome. 
# - correct for loss of signals
# effective genome size: https://deeptools.readthedocs.io/en/develop/content/feature/effectiveGenomeSize.html
# peak detection - d/2, slides across the genome with a window of 2d, modelling by Poisson distribution
# The Poisson is a one parameter model, where the parameter λ is the expected number of reads in that window.
# MACS uses a dynamic parameter, λlocal, defined for each candidate peak
# The lambda parameter is estimated from the control sample and is deduced by taking the maximum value across various window sizes:
# λlocal = max(λBG, λ1k, λ5k, λ10k).
# captures local biases, robust against differences
# However, in MACS2, p-values are now corrected for multiple comparison using the Benjamini-Hochberg correction.
module load gcc/6.2.0  python/2.7.12 macs2/2.1.1.20160309
mkdir -p ~/chipseq/results/macs2
cd ~/chipseq/results/
cp /n/groups/hbctraining/chip-seq/bowtie2/*.bam ~/chipseq/results/bowtie2/
# seven major functions (here only callpeak)
macs2 COMMAND -h will show the commands
macs2 callpeak
# -t: The IP data file (this is the only REQUIRED parameter for MACS)
# -c: The control or mock data file
# -f: format of input file; Default is “AUTO” which will allow MACS to decide the format automatically.
# -g: mappable genome size which is defined as the genome size which can be sequenced; some precompiled values provided.
# --outdir: MACS2 will save all output files into speficied folder for this option
# -n: The prefix string for output files
# -B/--bdg: store the fragment pileup, control lambda, -log10pvalue and -log10qvalue scores in bedGraph files
# -s: size of sequencing tags. Default, MACS will use the first 10 sequences from your input treatment file to determine it
# --bw: The bandwidth which is used to scan the genome ONLY for model building. Can be set to the expected sonication fragment size.
# --mfold: upper and lower limit for model building
# p value relaxing tied to peak widths - different behavior
# -q: q-value (minimum FDR) cutoff
# -p: p-value cutoff (instead of q-value cutoff)
# --nolambda: do not consider the local bias/lambda at peak candidate regions
# --broad: broad peak calling
# Ideally, if you relaxed the thresholds, you would simply get more peaks but with MACS2 relaxing thresholds also results in wider peaks.
macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep1_aln.bam \
	-c bowtie2/H1hesc_Input_Rep1_aln.bam \
 	-f BAM -g 1.3e+8 \
	-n Nanog-rep1 \
	--outdir macs2 2> macs2/Nanog-rep1-macs2.log # redirect to standard error file
macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep2_aln.bam -c bowtie2/H1hesc_Input_Rep2_aln.bam -f BAM -g 1.3e+8 --outdir macs2 -n Nanog-rep2 2> macs2/Nanog-rep2-macs2.log
macs2 callpeak -t bowtie2/H1hesc_Pou5f1_Rep1_aln.bam -c bowtie2/H1hesc_Input_Rep1_aln.bam -f BAM -g 1.3e+8 --outdir macs2 -n Pou5f1-rep1 2> macs2/Pou5f1-rep1-macs2.log
macs2 callpeak -t bowtie2/H1hesc_Pou5f1_Rep2_aln.bam -c bowtie2/H1hesc_Input_Rep2_aln.bam -f BAM -g 1.3e+8 --outdir macs2 -n Pou5f1-rep2 2> macs2/Pou5f1-rep2-macs2.log
# output files are narrowPeak file - used by ENCODE, BED 4+6 format
# 6 files output to the results directory for each of the 4 samples, so a total of 24 files:
# _peaks.narrowPeak: BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue
# _peaks.xls: a tabular file which contains information about called peaks. Additional information includes pileup and fold enrichment
# _summits.bed: peak summits locations for every peak. To find the motifs at the binding sites, this file is recommended
# _model.R: an R script which you can use to produce a PDF image about the model based on your data and cross-correlation plot
# _control_lambda.bdg: bedGraph format for input sample
# _treat_pileup.bdg: bedGraph format for treatment sample
# summary of peaks per sample: 
wc -l *.narrowPeak
# generate plots in R
module load gcc/6.2.0 R/3.4.1
# Rscript Nanog-rep1_model.r
# cross-correlation plot
# narrow peak calling lesson: https://hbctraining.github.io/Intro-to-ChIPseq/lessons/peak_calling_spp.html
# for localized protein positions from unpaired reads
### ChIPQC for quality assessment
# compute a number of quality metrics and generates a ChIPseq experiment quality report
######################## in R studio
# Open up a new R script (‘File’ -> ‘New File’ -> ‘Rscript’), and save it as chipQC.R
library(BiocManager)
install("ChIPQC")
# move over the BAM files _aln.bam, indices _aln.bam.bai and also narrowPeak files
~/chipseq/results/bowtie2
## Load sample data
samples <- read.csv('meta/samplesheet_chr12.csv')
View(samples)
# SampleID: Identifier string for sample
# Tissue, Factor, Condition: Identifier strings for up to three different factors (You will need to have all columns listed. If you don’t have infomation, then set values to NA)
# Replicate: Replicate number of sample
# bamReads: file path for BAM file containing aligned reads for ChIP sample
# ControlID: an identifier string for the control sample
# bamControl: file path for bam file containing aligned reads for control sample
# Peaks: path for file containing peaks for sample
# PeakCaller: Identifier string for peak caller used. Possible values include “raw”, “bed”, “narrow”, “macs”
# Create ChIPQC object
chipObj <- ChIPQC(samples, annotation="hg19")
register(SerialParam()) 
# Create ChIPQC report
ChIPQCreport(chipObj, reportName="ChIP QC report: Nanog and Pou5f1", reportFolder="ChIPQCreport")
# assess the distribution of signal within enriched regions, within/across expected annotations, across the whole genome, and within known artefact regions
# Read characteristics, Enrichment of reads in peaks, Peak signal strength, Peak profiles
# metrics include read depth, read length, and duplication rate. The read depth and length
# strong enrichment of reads in peaks, including RiP (reads in peaks, s/n ratio, 5% or higher), SSD, and RiBL
# SSD: uniformity of coverage of reads across the genome
# a higher SSD is more indicative of better enrichment
# regions of artificially high signal
# ‘Coverage histogram’ - A ChIP sample with good enrichment should have a reasonable ”tail”, or more positions (higher values on the y-axis) having higher sequencing depth
# Lower RiBL percentages are better than higher. - blacklisted regions reads, centromeres, telomeres, satellites
# The signal from blacklisted regions has been shown to contribute to confound peak callers and fragment length estimation

### Peak signal strength
# peak signal strength - rfraglength and relcc (relative cross-correl. coeff.) - if larger than 1 for all ChIPs - good s/n
# Fragl should be roughly the same as the fragment length picked in size selection step during library prep
# cross-correlation are calculated by Pearson linear correlation between coverage for each complementary base
# At strand shift of zero, the Pearson correlation between the two vectors is 0.
# At strand shift of 100bp, the Pearson correlation between the two vectors is 0.389.
# At strand shift of 175bp, the Pearson correlation between the two vectors is 0.831.
# are computed for every peak from each chromosome, values multiplied by a scaling factor and summed across from all chromosomes
# cross-correlation plot typically produces two peaks: a peak of enrichment corresponding to the predominant fragment length
# (highest correlation value) and a peak corresponding to the read length (“phantom” peak)
# RelCC (or RSC) value is computed using the minimum and maximum cross-correlation values
# extra info: https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionV/lessons/CC_metrics_extra.html
# Low RSC values: poor quality ChIP, low read sequence quality, mismappings, shallow sequencing depth or a combination
# also bio reasons (few binding sites)
# ex of strong signal - zinc-finger transcription factor (45000 or 60000 peaks) - big peak with a small spike on side (reads)
# weak signal - broad scattered non-smooth peakds, two peaks - one at peak shift and one at read length
# no signal - little or no peak for fragment length - stronger peak is the read length
### Peak profiles
# relative enrichment of genoimc intervals (REGI)
# see where reads map in terms of various genomic features
# relative enrichment of peaks in all samples and make a note of that (heatmap), enrichment in specific regions
# ideally symmetric but depends on system studied
# important to evaluate sample similarity
# within sample group vs between sample groups
# low quality data: strength/efficiency and specificity of immunoprecipitation, fragmentation or digestion (chromatin quality, sonication etc)

#### Handling ChIP-Seq replicates
# variability, benchmarking, minimum of 3 replicates (biological, 2 should be consistant)
# metrics to evaluate reproducibility needed
# IDR and BEDtools
# need to assess peaks present in only the replicates before moving to different TFs
# taking overlapping peak calls across replicates and assess differences in binding regions
# evaluation of reproducibility
# bedtools - takes genome coordinate information and performs relatively simple arithmetic, like combining, 
# subsetting, intersecting, etc., to obtain all sorts of information

## irreproducibility discovery rate framework
# compares a pair of ranked lists of regions/peaks and assigns values that reflect its reproducibility.
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431496/
# avoids cutoffs, no arbitrary thresholds, rank-based, no input calibration needed
# Three main IDR components: correspondence curve (qualitative), 
# inference procedure - summarizes proportion of non/reproducible signals, quantitative (what is noise)
# irreproducible discovery rate - derives significance value from no. 2, 0.05 IDR = 5% chance of being irreproducibke discovery
# true, pooled pseudo, self consistency
# we should be using the full dataset, and if you are interested the full BAM files can be downloaded from ENCODE, 
# however for timeliness and consistency we will continue with our subsetted data for this lesson.
# RUN MACS2 LESS STRINGENTLY
# sampling both s and n distributions
# narrowPeak files have to be sorted by the log10(p-value) column
###DO NOT RUN THIS###
# Call peaks using a liberal p-value cutoff
macs2 callpeak -t treatFile.bam -c inputFile.bam -f BAM -g 1.3e+8 -n macs/NAME_FOR_OUPUT -B -p 1e-3  2> macs/NAME_FOR_OUTPUT_macs2.log
#Sort peak by -log10(p-value)
sort -k8,8nr NAME_OF_INPUT_peaks.narrowPeak > macs/NAME_FOR_OUPUT_peaks.narrowPeak 
# SPP - Works out of the box
# MACS1.4 - DO NOT use with IDR
# MACS2 - Works well with IDR with occasional problems of too many ties in ranks for low quality ChIP-seq data.
# HOMER - developers have a detailed pipeline and code (in beta) for IDR analysis with HOMER at https://github.com/karmel/homer-idr
# PeakSeq - Run with modified PeakSeq parameters to obtain large number of peaks
# HotSpot, MOSAiCS, GPS/GEM, …
# IDR https://github.com/nboley/idr
module load gcc/6.2.0  python/3.6.0
module load idr/2.0.2
# create the chipseq results IDR directory
# copy over sorted narrowPeak files
# evluate consistency
idr -h # show idr parameters
# Nanog
idr --samples Nanog_Rep1_sorted_peaks.narrowPeak Nanog_Rep2_sorted_peaks.narrowPeak \
--input-file-type narrowPeak \
--rank p.value \
--output-file Nanog-idr \
--plot \
--log-output-file nanog.idr.log
# POu5f1
idr --samples Pou5f1_Rep1_sorted_peaks.narrowPeak Pou5f1_Rep2_sorted_peaks.narrowPeak \
--input-file-type narrowPeak \
--rank p.value \
--output-file Pou5f1-idr \
--plot \
--log-output-file pou5f1.idr.log
# output - frist 10 columns, narrowPeak file, column 5 - scaled IDR value
# column 11 and 12 - local and global IDR, columns 13 to 16 - replicate 1, 17 to 20 - replicate 2
wc -l *-idr # how many common peaks
# filter files IDR < 0.05 using awk
awk '{if($5 >= 540) print $0}' Nanog-idr | wc -l
awk '{if($5 >= 540) print $0}' Pou5f1-idr | wc -l
# output png files as well

# peak consistency between pooled pseudoreplicates
# if IDR analysis on the pooled pseudo-replicates results in a number of peaks that are similar 
# (within a factor of 2) these are truly good replicates.

# example of such a script
#!/bin/sh
# USAGE: sh pseudorep_idr.sh <input BAM rep1> <chip BAM rep1> <input BAM rep2> <chip BAM rep2> <NAME for IDR output>
# This script will take the BAM files and perform the following steps: 
    ## Merge BAMs for ChiP files,
    ## Shuffle reads and split into two new BAM files (pseudo-replicates), 
    ## Merge BAMs for Input files,
    ## Shuffle reads and split into two new BAM files (pseudo-replicates), 
    ## Call peaks on pseudo-replicates with MACS2 , 
    ## Sort peaks called on pseudo-replicates,
    ## IDR analysis using pseudo-replicate peak calls
# Please use the following SLURM directives:
	## -t 0-12:00
	## -p short
	## --mem=40G
date 
inputFile1=`basename $1`
treatFile1=`basename $2`
inputFile2=`basename $3`
treatFile2=`basename $4`
EXPT=$5
NAME1=`basename $treatFile1 _full.bam`
NAME2=`basename $treatFile2 _full.bam`
# Make Directories
mkdir -p /n/scratch2/mm573/idr_chipseq/macs
mkdir -p /n/scratch2/mm573/idr_chipseq/pooled_pseudoreps
mkdir -p /n/scratch2/mm573/idr_chipseq/tmp
# Set paths
baseDir=/n/groups/hbctraining/ngs-data-analysis-longcourse/chipseq/bowtie2
macsDir=/n/scratch2/mm573/idr_chipseq/macs
outputDir=/n/scratch2/mm573/idr_chipseq/pooled_pseudoreps
tmpDir=/n/scratch2/mm573/idr_chipseq/tmp
#Merge treatment BAMS
echo "Merging BAM files for pseudoreplicates..."
samtools merge -u ${tmpDir}/${NAME1}_${NAME2}_merged.bam $baseDir/${treatFile1} $baseDir/${treatFile2}
samtools view -H ${tmpDir}/${NAME1}_${NAME2}_merged.bam > ${tmpDir}/${EXPT}_header.sam
#Split merged treatments
nlines=$(samtools view ${tmpDir}/${NAME1}_${NAME2}_merged.bam | wc -l ) # Number of reads in the BAM file
nlines=$(( (nlines + 1) / 2 )) # half that number
samtools view ${tmpDir}/${NAME1}_${NAME2}_merged.bam | shuf - | split -d -l ${nlines} - "${tmpDir}/${EXPT}" # This will shuffle the lines in the file and split it
 into two SAM files
cat ${tmpDir}/${EXPT}_header.sam ${tmpDir}/${EXPT}00 | samtools view -bS - > ${outputDir}/${EXPT}00.bam
cat ${tmpDir}/${EXPT}_header.sam ${tmpDir}/${EXPT}01 | samtools view -bS - > ${outputDir}/${EXPT}01.bam
#Merge input BAMS
echo "Merging input BAM files for pseudoreplicates..."
samtools merge -u ${tmpDir}/${NAME1}input_${NAME2}input_merged.bam $baseDir/${inputFile1} $baseDir/${inputFile2}
#Split merged treatment BAM
nlines=$(samtools view ${tmpDir}/${NAME1}input_${NAME2}input_merged.bam | wc -l ) # Number of reads in the BAM file
nlines=$(( (nlines + 1) / 2 )) # half that number
samtools view ${tmpDir}/${NAME1}input_${NAME2}input_merged.bam | shuf - | split -d -l ${nlines} - "${tmpDir}/${EXPT}_input" # This will shuffle the lines in the file and split in two 
cat ${tmpDir}/${EXPT}_header.sam ${tmpDir}/${EXPT}_input00 | samtools view -bS - > ${outputDir}/${EXPT}_input00.bam
cat ${tmpDir}/${EXPT}_header.sam ${tmpDir}/${EXPT}_input01 | samtools view -bS - > ${outputDir}/${EXPT}_input01.bam
#Peak calling on pseudoreplicates
echo "Calling peaks for pseudoreplicate1 "
macs2 callpeak -t ${outputDir}/${EXPT}00.bam -c ${outputDir}/${EXPT}_input00.bam -f BAM -g hs -n $macsDir/${NAME1}_pr -B -p 1e-3  2> $macsDir/${NAME1}_pr_macs2.log
echo "Calling peaks for pseudoreplicate2"
macs2 callpeak -t ${outputDir}/${EXPT}01.bam -c ${outputDir}/${EXPT}_input01.bam -f BAM -g hs -n $macsDir/${NAME2}_pr -B -p 1e-3  2> $macsDir/${NAME2}_pr_macs2.log
#Sort peak by -log10(p-value)
echo "Sorting peaks..."
sort -k8,8nr $macsDir/${NAME1}_pr_peaks.narrowPeak | head -n 100000 > $macsDir/${NAME1}_pr_sorted.narrowPeak
sort -k8,8nr $macsDir/${NAME2}_pr_peaks.narrowPeak | head -n 100000 > $macsDir/${NAME2}_pr_sorted.narrowPeak
#Independent replicate IDR
echo "Running IDR on pseudoreplicates..."
idr --samples $macsDir/${NAME1}_pr_sorted.narrowPeak $macsDir/${NAME2}_pr_sorted.narrowPeak --input-file-type narrowPeak --output-file ${EXPT}_pseudorep-idr --rank p.value --plot
# Remove the tmp directory
rm -r $tmpDir

# self-consistency - optional step, creating pseudoreplicates for each replicate by 
# randomly splitting reads, running the same workflow
# threshold guidelines: 
# If starting with < 100K pre-IDR peaks for large genomes (human/mouse): 
# For true replicates and self-consistency replicates an IDR threshold of 0.05 is more appropriate
# Use a tighter threshold for pooled-consistency since pooling and subsampling equalizes the pseudo-replicates in terms of data quality.
# Err on the side of caution and use more stringent IDR threshold of 0.01

#### Differential peak calling - DiffBind (R) compare peak calls between groups
# differential enrichment analysis
# https://hbctraining.github.io/Intro-to-ChIPseq/lessons/08_diffbind_differential_peaks.html
# many tools differing by input, replicates, statistical model, signal type
# peaksets, overlapping and merging them, counting seq reads, overlapping intervals in peak sets
# stat. significantly differentially bound sets
# details: http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf
# Replicate peak calls are used individually, and not merged.
# a new R script
# set up using the section ChIPQC using R, get all files in there
# The samplesheet that we used for ChIPQC is also required here
library(DiffBind)
library(tidyverse)
# read peaksets and metadata
samples <- read.csv('meta/samplesheet_chr12.csv')
dbObj <- dba(sampleSheet=samples)
# A region is considered for the consensus set if it appears in more than two of the samples
dbObj
# compute count information for each of the peaks/regions in the consensus set
# recentre peaks and trim
dbObj <- dba.count(dbObj, bUseSummarizeOverlaps=TRUE)
# exploratory data analysis - PCA plot
dba.plotPCA(dbObj,  attributes=DBA_FACTOR, label=DBA_ID)
# correlation heatmap, replicates should cluster together
plot(dbObj)
# compare samples to one another
dbObj <- dba.contrast(dbObj, categories=DBA_FACTOR, minMembers = 2)
# diffbing or deseq2 or edgeR - each produces p value and FDR
# statistically significantly differentially bound between sample groups
dbObj <- dba.analyze(dbObj, method=DBA_ALL_METHODS)
dba.show(dbObj, bContrasts=T) # shows summary of all the results, edgeR is more stringent, lack of complete agreement with RNA-seq tools
# default padj is <0.05, if 0.01 use th = 0.01
#plotting only the regions identified by deseq2
dba.plotPCA(dbObj, contrast=1, method=DBA_DESEQ2, attributes=DBA_FACTOR, label=DBA_ID)
# also plot edgeR later
# visualization - edgeR has fewer peaks, to see overlapping peaks: 
dba.plotVenn(dbObj,contrast=1,method=DBA_ALL_METHODS)
# MA plots - to visualize effect of normalization on data, what is differentially bound
dba.plotMA(dbObj, method=DBA_DESEQ2) # red points - deseq2 sites, plots show differentially bound sites appear 
# to have an absolute log fold difference of 2 at least
# This same data can also be shown with the concentrations of each sample groups plotted against each other.
dba.plotMA(dbObj, bXY=TRUE)
# how the reads are distributed amongst the different classes of differentially bound sites and sample groups
pvals <- dba.plotBox(dbObj)# returnsa matrix of p values
# extract full results
res_deseq <- dba.report(dbObj, method=DBA_DESEQ2, contrast = 1, th=1)
res_deseq
# Write to file
out <- as.data.frame(res_deseq)
write.table(out, file="results/Nanog_vs_Pou5f1_deseq2.txt", sep="\t", quote=F, row.names=F)
# Create bed files for each keeping only significant peaks (p < 0.05)
nanog_enrich <- out %>% 
  filter(FDR < 0.05 & Fold > 0) %>% 
  select(seqnames, start, end)
# Write to file
write.table(nanog_enrich, file="Nanog_enriched.bed", sep="\t", quote=F, row.names=F, col.names=F)
pou5f1_enrich <- out %>% 
  filter(FDR < 0.05 & Fold < 0) %>% 
  select(seqnames, start, end)
# Write to file
write.table(pou5f1_enrich, file="Pou5f1_enriched.bed", sep="\t", quote=F, row.names=F, col.names=F)
# BED files are used for downstream visualization
# BED files do not contain headers so for sdownstream visualization these need to be added

##### Visualization of peaks
# The first part of ChIP-sequencing analysis uses common processing pipelines,
# which involves the alignment of raw reads to the genome, data filtering, and identification of enriched signal regions (peak calling). 
# In the second stage, individual software programs allow detailed analysis of those peaks, biological interpretation, and visualization of ChIP-seq results.
# bigWig files - use BAM and convert to bigWig - indexed binary format useful for dense, continuous data, using deepTools (Python)
# https://deeptools.readthedocs.io/en/latest/content/tools/bamCoverage.html?highlight=bigwig
cd ~/chipseq/results/
mkdir -p visualization/bigWig visualization/figures
module load gcc/6.2.0  python/2.7.12
module load deeptools/3.0.2 
# create an index file for each one of our BAM files
# indexing bam files with samtools
module load samtools/1.9
for file in ~/chipseq/results/bowtie2/*aln.bam
do
samtools index $file
done
# also possible with single line:
for file in ~/chipseq/results/bowtie2/*aln.bam; do samtools index $file; done
# creating bitWig files
# normalizeUsing: Possible choices: RPKM, CPM, BPM, RPGC. We will use BPM (Bins Per Million), which is similar to TPM in RNA-seq. 
# BPM (per bin) = number of reads per bin / sum of all reads per bin (in millions).
# binSize: size of bins in bases
# smoothLength: defines a window, larger than the binSize, to average the number of reads over. This helps produce a more continuous plot.
# centerReads: reads are centered with respect to the fragment length as specified by extendReads. 
# This option is useful to get a sharper signal around enriched regions.

bamCoverage -b bowtie2/H1hesc_Nanog_Rep2_aln.bam \
-o visualization/bigWig/H1hesc_Nanog_Rep2.bw \
--binSize 20 \
--normalizeUsing BPM \
--smoothLength 60 \
--extendReads 150 \
--centerReads \
-p 6 2> ../logs/Nanog_rep2_bamCoverage.log

bamCoverage -b bowtie2/H1hesc_Pou5f1_Rep1_aln.bam \
-o visualization/bigWig/H1hesc_Pou5f1_Rep1.bw \
--binSize 20 \
--normalizeUsing BPM \
--smoothLength 60 \
--extendReads 150 \
--centerReads \
-p 6 2> ../logs/Pou5f1_rep1_bamCoverage.log

# reate a bigWig file in which we normalize the ChIP against the input we would use bamCompare. 
# The command is quite similar to bamCoverage, the only difference being you require two files as input (b1 and b2)

bamCompare -b1 bowtie2/H1hesc_Pou5f1_Rep1_aln.bam \
-b2 bowtie2/H1hesc_Input_Rep1_chr12_aln.bam \
-o visualization/bigWig/H1hesc_Pou5f1_Rep1_bgNorm.bw \
--binSize 20 \
--normalizeUsing BPM \
--smoothLength 60 \
--extendReads 150 \
--centerReads \
-p 6 2> ../logs/Pou5f1_rep1_bamCompare.log

# with a lot of samples wrte a job submission script in a loop
# profile plots and heatmaps
# plotHeatmap and plotProfile - under one command computeMatrix which calculates values based on user-supplied input files
# can be decided to calculate values about a reference pointor scaled regions, binning size
the two subfunctions - change appearance etc
# computeMatrix only accep0s bigWigs or BED - intermediate file matrix
# TSS - transcription start sites

computeMatrix reference-point --referencePoint TSS \
-b 1000 -a 1000 \
-R ~/chipseq/results/visualization/chr12_genes.bed \
-S /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Nanog*.bw \
--skipZeros \
-o ~/chipseq/results/visualization/matrixNanog_TSS_chr12.gz \
-p 6 \
--outFileSortedRegions ~/chipseq/results/visualization/regions_TSS_chr12.bed

computeMatrix reference-point --referencePoint TSS \
-b 1000 -a 1000 \
-R ~/chipseq/results/visualization/chr12_genes.bed \
-S /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Pou5f1*.bw \
--skipZeros \
-p 6 \
-o ~/chipseq/results/visualization/matrixPou5f1_TSS_chr12.gz \
--outFileSortedRegions ~/chipseq/results/visualization/regionsPou5f1_TSS_chr12.bed

# region genes can be obtained from http://rohsdb.cmb.usc.edu/GBshape/cgi-bin/hgTables
# creating the plot profile - density plot
plotProfile -m visualization/matrixNanog_TSS_chr12.gz \
-out visualization/figures/TSS_Nanog_profile.png \
--perGroup \
--colors green purple \
--plotTitle "" --samplesLabel "Rep1" "Rep2" \
--refPointLabel "TSS" \
-T "Nanog read density" \
-z ""
# or the heatmap
plotHeatmap -m visualization/matrixNanog_TSS_chr12.gz \
-out visualization/figures/TSS_Nanog_heatmap.png \
--colorMap RdBu \
--whatToShow 'heatmap and colorbar' \
--zMin -4 --zMax 4  
# do the same for the other gene as well
# both in a single plot
plotHeatmap -m visualization/matrixPou5f1_TSS_chr12.gz \
-out visualization/figures/TSS_Pou5f1_profile-heatmap.png \
--colorMap RdBu \
--zMin -2 --zMax 2  
# explore the documentation 

# visualization of enrichment in Diff enriched regions
# almost all of the peaks that were identfied were specific to Nanog and only one region that had significantly higher enrichment in Pou5f1
# using deepTools - reference point was changed to scale region
# Nanog had 33 regions as increased in enrichment compared to Pouf1
computeMatrix scale-regions \
-R ~/chipseq/results/visualization/Nanog_enriched.bed \
-S /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Pou5f1*.bw /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Nanog*.bw \
--skipZeros \
-p 6 \
--regionBodyLength 2000 \
-a 500 -b 500 \
-o ~/chipseq/results/visualization/matrixAll_Nanog_binding_sites.gz


$ plotProfile -m visualization/matrixAll_Nanog_binding_sites.gz \
-out visualization/figures/Allsamples_NanogSites_profile.png \
--perGroup  --plotTitle "" \
--samplesLabel "Pou5f1-Rep1" "Pou5f1-Rep2" "Nanog-Rep1" "Nanog-Rep2" \
-T "Nanog only binding sites"  -z "" \
--startLabel "" \
--endLabel "" \
--colors red red darkblue darkblue

# Pouf1 had only 1 significant binding site
computeMatrix scale-regions \
-R ~/chipseq/results/visualization/Pou5f1_enriched.bed \
-S /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Pou5f1*.bw /n/groups/hbctraining/chip-seq/full-dataset/bigWig/Encode_Nanog*.bw \
--skipZeros \
-p 6 \
--regionBodyLength 2000 \
-a 500 -b 500 \
-o ~/chipseq/results/visualization/matrixAll_Pou5f1_binding_sites.gz 


$ plotProfile -m visualization/matrixAll_Pou5f1_binding_sites.gz \
-out visualization/figures/Allsamples_Pou5f1Sites_profile.png \
--perGroup  --plotTitle "" \
--samplesLabel "Pou5f1-Rep1" "Pou5f1-Rep2" "Nanog-Rep1" "Nanog-Rep2" \
-T "Pou5f1 only binding sites"  -z "" \
--startLabel "" --endLabel "" \
--colors red red darkblue darkblue

# qualitative assessment with IGV to visualize BigWig and BED files
# https://software.broadinstitute.org/software/igv/

# scp username@transfer.rc.hms.harvard.edu:/path/to/file_on_O2 Path/to/directory/local_machine allows copying between different hosts
# locate the BED files we generated from the differential enrichment analysis using DiffBind
# Start IGV.
# Load the Human genome (hg19) into IGV using the dropdown menu at the top left of your screen. 
# Note: there is also an option to “Load Genomes from File…” under the “Genomes” pull-down menu - this is useful when working with non-model organisms.
# Load the 2 bigWig files and 4 BED files using the “Load from File…“ option under the “File” pull-down menu.

#### Annotation and Functional Analysis
# peak annotation - ChIP seeker and R Bioconductor
BiocManager::install("ChIPseeker")
# Load libraries
library(ChIPseeker)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(EnsDb.Hsapiens.v75)
library(clusterProfiler)
library(AnnotationDbi)
library(org.Hs.eg.db)
# high confidence peaks are annotated, a set of them from full data (post-IDR analysis), BED files
# Load data
samplefiles <- list.files("data/idr-bed", pattern= ".bed", full.names=T)
samplefiles <- as.list(samplefiles)
names(samplefiles) <- c("Nanog", "Pou5f1")
# assign annotation databases http://bioconductor.org/packages/3.5/data/annotation/
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
# algorithm looks for nearest genomic TSS
# annotatePeak function - parameters to specify a max distance from TSS
# retrive annotations
peakAnnoList <- lapply(samplefiles, annotatePeak, TxDb=txdb, 
                       tssRegion=c(-1000, 1000), verbose=FALSE)
peakAnnoList # look
# Assign peak data to variables
nanog <- readPeakFile(samplefiles[[1]])
pou5f1 <- readPeakFile(samplefiles[[2]])
# Plot covplot
covplot(nanog, weightCol="V5")
# Prepare the promotor regions
promoter <- getPromoters(TxDb=txdb, upstream=1000, downstream=1000)
# Calculate the tag matrix
tagMatrixList <- lapply(as.list(samplefiles), getTagMatrix, windows=promoter)
## Profile plots
plotAvgProf(tagMatrixList, xlim=c(-1000, 1000), conf=0.95,resample=500, facet="row")
# Plot heatmap
tagHeatmap(tagMatrixList, xlim=c(-1000, 1000), color=NULL)

plotAnnoBar(peakAnnoList)
plotDistToTSS(peakAnnoList, title="Distribution of transcription factor-binding loci \n relative to TSS") # feature distributions
nanog_annot <- data.frame(peakAnnoList[["Nanog"]]@anno) # annotations for each peak call written to file
# https://bioconductor.org/packages/release/bioc/vignettes/AnnotationDbi/inst/doc/IntroToAnnotationPackages.pdf
keytypes(TxDb.Hsapiens.UCSC.hg19.knownGene)
# Get the entrez IDs
entrez <- nanog_annot$geneId
# Return the gene symbol for the set of Entrez IDs
annotations_edb <- AnnotationDbi::select(EnsDb.Hsapiens.v75,
                                         keys = entrez,
                                         columns = c("GENENAME"),
                                         keytype = "ENTREZID")
# Change IDs to character type to merge
annotations_edb$ENTREZID <- as.character(annotations_edb$ENTREZID)
# Write to file
nanog_annot %>% 
  left_join(annotations_edb, by=c("geneId"="ENTREZID")) %>% 
  write.table(file="results/Nanog_peak_annotation.txt", sep="\t", quote=F, row.names=F)
# functional enrichment - R based
# biological themes - Gene Ontology, KEGG and Reactome
# over-representation analysis (GO, clusterProfiler)
# Run GO enrichment analysis 
ego <- enrichGO(gene = entrez, 
                    keyType = "ENTREZID", 
                    OrgDb = org.Hs.eg.db, 
                    ont = "BP", 
                    pAdjustMethod = "BH", 
                    qvalueCutoff = 0.05, 
                    readable = TRUE)
# Output results from GO analysis to a table
cluster_summary <- data.frame(ego)
write.csv(cluster_summary, "results/clusterProfiler_Nanog.csv")
# Dotplot visualization
dotplot(ego, showCategory=50)
# KEGG pathway enrichment
ekegg <- enrichKEGG(gene = entrez,
                 organism = 'hsa',
                 pvalueCutoff = 0.05)

dotplot(ekegg)
# comparing different samples enrichment (two different samples)
# Create a list with genes from each sample
genes = lapply(peakAnnoList, function(i) as.data.frame(i)$geneId)
# Run KEGG analysis
compKEGG <- compareCluster(geneCluster = genes, 
                         fun = "enrichKEGG",
                         organism = "human",
                         pvalueCutoff  = 0.05, 
                         pAdjustMethod = "BH")
dotplot(compKEGG, showCategory = 20, title = "KEGG Pathway Enrichment Analysis")
# functional enrichment - web-based tools: GREAT (Genomic Regions Enrichment of Annotations Tool), 20 different annotations
# https://hbctraining.github.io/Intro-to-ChIPseq/lessons/web_based_functional_analysis.html
# http://great.stanford.edu/public/html/demo.php - demo datasets
# motif discovery - MEME, DREME
# need a FASTA file of all genomic region sequences (from IDR BED files: https://hbctraining.github.io/Intro-to-ChIPseq/lessons/motif_analysis_prep.html)
# select merged as DREME input, enter email and job description, Fisher’s Exact Test
# also TomTom - if motifs resemble TF sites, match score and stat sites
# MEME-ChIP
#####################################################

# downloading from publically available databases - GEO, SRA, Ensembl latest genome assembly
wget ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Homo_sapiens/NCBI/GRCh38/Homo_sapiens_NCBI_GRCh38.tar.gz
tar -xzf Homo_sapiens_NCBI_GRCh38.tar.gz
# worm
wget ftp://ftp.ebi.ac.uk/pub/databases/wormbase/parasite/releases/WBPS10/species/acanthocheilonema_viteae/PRJEB4306/acanthocheilonema_viteae.PRJEB4306.WBPS10.genomic.fa.gz
# GEO
wget --recursive --no-parent -nd ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE50nnn/GSE50499/suppl/
wget -r -np -nd -R "index.html*" ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE50nnn/GSE50499/suppl/
# all data
tar -xvf GSE111889_RAW.tar 
for all in *.gz; do gunzip $all; done
curl -O ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE50nnn/GSE50499/suppl/GSE50499_GEO_Ceman_counts.txt.gz
# from SRA - study, sample, experiment, run
####################################################

#### ALLIGNMENT TOOLS AND THEORY
# genome mapping pipeline: usually use STAR, HISAT2, bowtie2 (spile-aware things), 
# then using htseq-count or featureCouns for genome counting or stringtie for transcript discovery and counting, homology-based blast2go for novel transcript anotation
# transcript mapping: Reads, RSEM, Kallisto, Sailfish, Salmon, transcript mapping and quantification
# assembly - reads (trinity and sculpture -> assembly into transcripts, then trinotate for novel transcript annotation)
## Transcript mapping - string matching (not that simple) - short reads, distinguish variants and sequencing errors, massive number, small insert size

# INDEX REFERENCE
# indexing a reference sequence - efficient way of searching, it can be queried any number of times (needed to be done only once! unless there is a better assembly released...)
# downloadable from Ensembl 
# indexing methods - Kallisto (hash-based), STAR and Salmon (suffix arrays), BWA and Bowtie2 (Burrows-Wheeler Transform)
# hash-based early - pick k-mer size, build lookup of every k-mer in reference map, break query into k-mers, seed and extend strategy, 100% match the query k-mer to reference, 0.1-1 sec per query, not feasible for NGS
# now - allow mismatches, use multiple seeds, slower and memory intensive
# suffix arrays - sorted table of suffixes (substrings of a string), all suffixes are sorted, large amount of memory required
# B-W transform - compressed suffix arrays, same characters together rather than sort alphabetically (Bowtie, SOAP2, BWA-MEM, diminished efficiency of string search operations, less memory needed)
# !!!!gtf = annotation file of a genome assembly must match the genome or transcriptome fasta file - same build and source!!!!
# SALMON - Fasta file of all transcripts of organism as reference, indexing by suffix array and hash table, outputs abundance estimates
# lightweight, quasialligner, faster and more efficient, improved accuracy for transcript-level quantification
## Quality control
# reads aligning, uniquely mapped, properly paired PE reads, genomic origin of reads, quality or RNA, transcript coverage etc. 
# by RNA-SeQC or Qualimap (input are bam/sam files and output is an html report file)
# sam file - mapping info, coordinates of alignment and strands, mismatches, quality of mapping (bam - binary version of sam)]
# gotten after alignment to genome fasta (guided with gtf - genome annotation file)
# Splice-aware alignment tools: HISAT2, STAR, MapSplice, SOAPSplice, Passion, SpliceMap, RUM, ABMapper, CRAC, GSNAP, HMMSplicer, Olego, BLAT
# non-splice aware, you will lose isoform information: Bowtie2, BWA, Novoalign (not free), SOAPaligner, but are good for aligning directly to genes

